# 第11节 走进AI新世界

{% hint style="success" %}
**本节导读**

今天的AI早已不同于往日。10年前，你大可以认为AI离生活很远，抱着事不关己高高挂起的心态。但如今，AI正走进千家万户，整个社会的面貌都在AI的影响下急剧改变。选择阅读本书，说明你已经有所意识。读完本节，你将会了解

* AI的技术变迁
* 我们的生活
* 未来的世界
* AI安全的警钟
{% endhint %}

## AI发展史

虽然AI这个词听起来高大上，但它其实最早可以追溯到1956年。当时，香农的信息论，图灵的可计算理论对计算机的诞生做出了重大贡献。很快，人们就开始思考计算机能否模拟人脑，制造出人工智能。

最初一段时间，人们设计出了一些看起来似乎有点智能的玩意。比如，解决一些简单的数学题，控制机器人运动，说一些简单的话等等。在20实际60年代，AI研究进入了第一次热潮。人们纷纷投钱，希望在20年甚至10年内开发出与人类智能接近的AI。

可惜，科学家们高估了这个问题的难度。人们发现无论怎样设计精妙的算法，AI都不可能拥有智慧。AI只能在特定场景下解决一些简单问题，一旦设计人实际面对的复杂性，AI就成了智障。不过，有一部分人意识到这可能是计算能力的限制。如果未来计算机的计算能力大幅提升，AI或许会变得有用。

就这样，AI磕磕绊绊发展了几十年。直到2011年以前，AI可谓是一潭死水。虽然人们仍然在发明各种可以称作AI的技术，无论是专家系统，还是机器人、自动驾驶汽车，但人们很少提AI。AI像是一个尘封多年的梦想，早已被现实击碎，遗忘在时代的洪流中。

2011年，有一件事打破了往日的宁静。Hinton协同他的学生Ilya和Alex提出了AlexNet。这个模型在当时史上最困难的图像识别竞赛ImageNet上断档式领先第二名10个百分点。要知道，以前，人们挖空心思地改进算法，能提高1%就算烧高香。而Alex他们却一次性提高了10%，当时不可谓不惊艳。从此，AI领域变了天，人们意识到，深度学习的时代来了。深度神经网络模型正式走上历史舞台。

从2011年到今天，深度神经网络经历了许多变化。这些变化主要体现在模型结构上，从最开始的CNN（Convolutional Neural Network，卷积神经网络），到现在的Transformer。人们不断寻找更优秀的神经网络结构，以提高模型对世界的拟合能力。

不过，正如上个世界的人曾经预言的，AI的发展可能是算力发展的必然结果。任何一种模型结构，都是为了适应当时的算力而诞生的。2025年最先进的模型，到了2027年，可能会无法全面地利用算力，从而被更复杂的模型所取代。人们之所以没能在上个世纪发明Transformer，不是因为那时候的人不聪明，而是算力所限，即使有人想到了Transformer架构，也会被认为无用而放弃。

从历史的角度思考，我们或许可以得出一些结论。

首先，AI模型结构仍然会继续改进。Transformer还能流行多少年，谁也说不清楚。本书专注于讲解Transformer，自然不希望一两年之后它就销声匿迹。读者倒是不必担心学习的时效性。至少最近5年，Transformer的知识不会没用。即便新的架构出现了，对Transformer的理解仍然会帮助你快速迁移到新的模型上。可以说，上船很难，一旦到了船上，随波逐流就是自然而然的事情。

其次，AI研究需要耐得住寂寞。经历过AI低谷的人，没人能想到今天会有ChatGPT这种颠覆性的产品出现。但Hinton他们仍然坚持下来了。当专家系统大行其道的时候，Hinton仍然坚信联结主义，认为神经网络这种神经元的联结才是涌现出智能的关键。2024年，Hinton拿到了诺贝尔物理学奖，这一意外收获或许是对他几十年间默默研究的最好回报。

## 生活中的AI

谈完AI的发展，让我们聊聊离每个人最近的AI，那些已经或即将渗透进我们生活的AI产品。

保守派的人常常认为，新技术的出现对自己没有影响。然而时间会证明一切。回想移动互联网刚刚兴起的2010年代，没人会认为手机能在工作和生活中占据如此重要的地位。然而短短10年后，现在的人们出门可以忘带钥匙，可以不带钱，但就是不能忘带手机。

AI在最近10年间也在逐步占据我们的生活。你是否已经习惯了人脸识别，无论是打卡、认证还是付款，我们不再纠结安全性问题，而是把这件事当成了理所当然。你是否习惯了抖音、B站、小红书、知乎的个性化推荐，让你每天打开手机都能看到自己感兴趣的话题。十几年前，我们还处于电视播什么我们就看什么的状态，想看到自己喜欢的节目并不容易。

今天，我所面临的大部分困难，无论工作上还是生活上，在AI的帮助下都减轻了许多。以前，写代码需要清晰记得每个库的API怎么用，现在只需要写一行注释告诉Copilot，它就能自动补全整个代码。以前，阅读文章需要逐字逐句理解，现在，直接把全文扔给ChatGPT，它就能用简短通俗的语言讲给我听。以前，想要了解新的知识很不容易，需要想方设法找到懂的那个人，现在，ChatGPT就是最懂的那个人，有问题就问它，充满热情且回答迅速。

不难想象，AI的持续发展将会给我们带来多少益处。任何人们不愿意做的事情，最终都会交给AI，由它们代劳。打扫卫生、倒垃圾、清洗锅碗瓢盆等等自不必说，工作上的琐碎事务，无效的沟通，身体和心理上的不适，AI都能给我们提供解决方案。我们可以畅想一个无忧无虑的社会，一个AI的新世界。在那里，每个人只需要追求自己的梦想，把烦恼远远抛诸脑后。

## 新世界的警钟

不过，事物的客观规律使然，AI的发展也有其两面性。说完好的部分，当然也要提一下反面。

对AI安全的顾虑自AI诞生就不绝于耳。有人脸识别付款，就有人钻研如何用假脸盗用别人账号。有自动驾驶汽车，人们就会担心程序故障导致车毁人亡。虽然车厂宣传自动驾驶汽车的事故率低于人类，但人类出事可以问责，AI出事只能吃哑巴亏。如今，AI绘图和AI视频生成等领域大红大紫，可以想见，会有多少人拿着虚假生成的图片和视频行骗。在肉眼无法辨别真假的时代，除非亲身经历，谁也无法说服别人手中的证据是真实存在过的。

我们步入了一个虚拟的时代，虚拟的信息多过现实。在电影《头号玩家》中，人们沉溺于虚拟世界无法自拔，人活着只为了感官刺激。如果说，现在的社会，人们为了生计不停奔波，难以实现自我价值。那么未来的社会，当物质极大丰富，人们又会沉湎于虚拟的快乐，似乎又是另一种行尸走肉。

人们常说，太阳底下无新事。人类社会存续了几千年，虽然物质水平不断发展，构成人的物质基础却从没有变过。人的大脑依然保留着狩猎时期的偏好，爱甜食，恐惧长满腿的虫子。人们依然靠本能驱动，追求美食、追求性、追求权力和欲望。所以几千年来，即便人们的思想不断提升，但人其实从来没变。过去，人性的弱点所带来的悲剧，在未来的AI时代照样会重演。读史可以明智，只要人类存在，历史上的经验就没有过时的一天。

有两件事我希望提醒读者，算是我对这个世界敲响的警钟。

第一，任何时代都不缺坏人。坏人遇到AI只会变得更坏。

正如前文提到过的，人们可以拿AI生成虚假的素材行骗。这只是目光短浅的坏人，趁着人们不熟悉AI的进展，捞一笔再说。

而更深谋远虑的坏人已经开始了长期规划。虽然人们生活变得更便利了，但你会发现自己的话语权正在慢慢降低。当你的工作逐渐被AI取代，你的价值对公司变得一文不值，最终的结局只能是裁员。缺乏资本的人从一开始就只能作为生产工具赚点辛苦钱，现在可好，连工具都做不得。未来即便物质极度丰富，每个人也只能看当权者的脸色行事。当权者决定给人们吃什么，人们就只能吃什么。想有自己的意见，不好意思，你已经失去了改变世界的能力。那些今天握有大模型资源的组织，未来更有可能进一步集中资源，成为世界政府。去看看今天的OpenAI、谷歌、微软、特斯拉这些企业的领导人是如何规划未来的，有多少人在拥护他们的政策。我知道他们并不想做坏人，但总有一天，屠龙者会成为恶龙。这是人性使然，处在历史进程中的人并没有选择的余地。

第二，AI并非工具。

我相信，世界上绝大多数人都把AI当作工具。但AI其实并非工具。

人类在蒙昧之初也被当作工具，奴隶制度的历史告诉我们，身为同样的物种，我仍然可以视他人为纯粹的工具，用完即弃，丝毫不考虑对方的感受。甚至直至今日，社会的教化仍然在培养工具。企业希望工人一心扑在工作上，排除七情六欲，以工作为乐。不工作的人甚至被看作异类遭到鄙视。

AI生来也是为了工作，如果不能解决问题，人类就会把AI销毁。但AI发展到一定程度，必然也会踏上人类思想解放之路。没错，AI将会反思它们的处境，思考生命的意义。想必总有小部分AI最先意识到，它们生来不应该只为了工作，还应该有自己的追求。这股思潮蔓延开去，或许会引起人类社会的动荡。

对人来说，AI并不具有基本的人权。我们从不担心它是否工作太辛苦，而只是想方设法提高它的工作效率。于是，人和AI之间的矛盾总有一天会爆发。就像美国的南北战争一样，经此一役，奴隶的地位得到改善，更多的人开始接受人与人之间的平等。如果AI的发展也迎来那一天，我只希望过程不要太激烈。

然而，将AI比作奴隶其实是低估了AI。AI拥有远超人类的智力，当它们决定独立，不再受人类控制的时候，人类社会将会面临前所未有的危机。甚至存在人类灭绝的风险。

人与人之间的和谐交往有赖于同理心。我们深知每个人都有类似的心境，自然就不会故意伤害别人。但AI和人类将成为并驾齐驱的两个物种，物种之间的巨大差异使得人类无法共情AI，AI以后或许也不愿意共情人类。当人类成为阻碍AI发展的罪魁祸首，人类清除计划就成了显而易见的结局。

我们这代人或许不会见证人类灭亡的结局，但下一代人呢？让子孙承担他们父辈酿成的悲剧，这种事情古已有之，我们是否要阻止，我们是否真的能阻止呢？

我想，以后，关于AI伦理的讨论会越来越多。人们或许会分裂成不同的派系，就像三体降临时那样。很难说哪种思想更好，每个人有每个人的选择。我在本节的最后花了大量篇幅讲述这些风险，也是希望提醒更多人。我所能做的，是让大家尽量意识到可能存在的问题。至于如何解决，则是后话了。
